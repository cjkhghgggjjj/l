import os
import subprocess
import sys
import traceback

# ===========================
# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
# ===========================
def install_packages():
    required_libs = [
        "flask",
        "onnxruntime", 
        "opencv-python-headless",
        "numpy",
        "requests",
        "pillow"
    ]
    
    print("ğŸ”§ Ø¨Ø¯Ø¡ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©...")
    
    for lib in required_libs:
        try:
            if lib == "opencv-python-headless":
                __import__("cv2")
            elif lib == "pillow":
                __import__("PIL")
            else:
                __import__(lib.split('-')[0])
            print(f"âœ… {lib} - Ù…Ø«Ø¨Øª Ù…Ø³Ø¨Ù‚Ø§Ù‹")
        except ImportError:
            print(f"ğŸ“¦ Ø¬Ø§Ø±ÙŠ ØªØ«Ø¨ÙŠØª {lib}...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", lib, "--quiet"])
                print(f"âœ… ØªÙ… ØªØ«Ø¨ÙŠØª {lib} Ø¨Ù†Ø¬Ø§Ø­")
            except Exception as e:
                print(f"âŒ ÙØ´Ù„ ØªØ«Ø¨ÙŠØª {lib}: {e}")

install_packages()

# ===========================
# Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
# ===========================
print("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ«Ø¨ÙŠØª...")

try:
    from flask import Flask, render_template_string, request, send_file, jsonify
    import cv2
    import numpy as np
    import requests
    import onnxruntime as ort
    from PIL import Image
    import io
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
except ImportError as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª: {e}")
    sys.exit(1)

# ===========================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# ===========================
app = Flask(__name__)

print("ğŸš€ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ AntelopeV2 Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API...")

# Ø±ÙˆØ§Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ AntelopeV2
MODEL_URLS = {
    "detection": "https://classy-douhua-0d9950.netlify.app/scrfd_10g_bnkps.onnx.index.js",
    "recognition": "https://classy-douhua-0d9950.netlify.app/glintr100.onnx.index.js",
    "genderage": "https://classy-douhua-0d9950.netlify.app/genderage.onnx.index.js",
    "landmarks_2d": "https://classy-douhua-0d9950.netlify.app/2d106det.onnx.index.js",
    "landmarks_3d": "https://classy-douhua-0d9950.netlify.app/1k3d68.onnx.index.js"
}

class APIOnlyFaceAnalysis:
    """ÙØ¦Ø© ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API ÙÙŠ ÙƒÙ„ Ù…Ø±Ø© Ø¨Ø¯ÙˆÙ† ØªØ®Ø²ÙŠÙ†"""
    
    def __init__(self):
        self.model_urls = MODEL_URLS
        self.initialized = True
        self.providers = ['CPUExecutionProvider']
    
    def prepare(self, ctx_id=0, det_size=(640, 640)):
        print("âœ… Ø¬Ø§Ù‡Ø² Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API")
        return True
    
    def get_model_from_api(self, model_name):
        """Ø¬Ù„Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©"""
        try:
            print(f"ğŸŒ Ø¬Ù„Ø¨ {model_name} Ù…Ù† API...")
            response = requests.get(self.model_urls[model_name], timeout=30)
            response.raise_for_status()
            
            session = ort.InferenceSession(
                response.content, 
                providers=self.providers
            )
            print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {model_name} Ø¨Ù†Ø¬Ø§Ø­")
            return session
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ {model_name}: {e}")
            return None
    
    def get(self, img):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API"""
        try:
            print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API...")
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            original_height, original_width = img.shape[:2]
            
            # Ø¬Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ´Ù Ù…Ù† API
            det_session = self.get_model_from_api("detection")
            if det_session is None:
                print("ğŸ”„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ´Ù Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ...")
                return self._get_fallback_faces(img)
            
            # ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡
            faces = self._detect_faces_from_api(img_rgb, original_width, original_height, det_session)
            
            # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ÙˆØ¬Ù‡
            for face in faces:
                # Ø¬Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ù…Ù† API
                rec_session = self.get_model_from_api("recognition")
                if rec_session:
                    face.embedding = self._get_embedding_from_api(img_rgb, face.bbox, rec_session)
                
                # Ø¬Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ù†Ø³ ÙˆØ§Ù„Ø¹Ù…Ø± Ù…Ù† API
                ga_session = self.get_model_from_api("genderage")
                if ga_session:
                    face.gender, face.age = self._analyze_gender_age_from_api(img_rgb, face.bbox, ga_session)
                else:
                    # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                    face.gender = 0 if np.random.random() > 0.5 else 1
                    face.age = np.random.randint(18, 60)
            
            return faces
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            traceback.print_exc()
            return self._get_fallback_faces(img)
    
    def _detect_faces_from_api(self, img_rgb, orig_w, orig_h, det_session):
        """ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† API"""
        class Face:
            def __init__(self, bbox, score):
                self.bbox = bbox
                self.det_score = score
                self.embedding = None
                self.gender = 0
                self.age = 25
        
        try:
            # Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
            input_size = (640, 640)
            
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
            img_resized = cv2.resize(img_rgb, input_size)
            img_normalized = img_resized.astype(np.float32)
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ±Ø© (Ù‡Ø°Ø§ Ù…Ù‡Ù… Ù„Ù„Ù†Ù…Ø§Ø°Ø¬)
            img_normalized = (img_normalized - 127.5) / 128.0
            
            # ØªØºÙŠÙŠØ± Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¥Ù„Ù‰ CHW
            img_chw = np.transpose(img_normalized, (2, 0, 1))
            img_batch = np.expand_dims(img_chw, axis=0)
            
            print(f"ğŸ“ Ø´ÙƒÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {img_batch.shape}")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            input_name = det_session.get_inputs()[0].name
            outputs = det_session.run(None, {input_name: img_batch})
            
            print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª: {len(outputs)}")
            for i, out in enumerate(outputs):
                print(f"   Ø§Ù„Ù…Ø®Ø±Ø¬ {i}: {out.shape}")
            
            faces = []
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
            if len(outputs) >= 2:
                # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ù‡ÙŠ bboxes Ùˆ scores
                try:
                    if len(outputs[0].shape) == 3:
                        bboxes = outputs[0][0]  # Ø´ÙƒÙ„ (1, N, 4)
                        scores = outputs[1][0]  # Ø´ÙƒÙ„ (1, N)
                    else:
                        bboxes = outputs[0]  # Ø´ÙƒÙ„ (N, 4)
                        scores = outputs[1]  # Ø´ÙƒÙ„ (N,)
                    
                    print(f"ğŸ” Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©: {len(scores)}")
                    
                    for i in range(len(scores)):
                        score = scores[i]
                        if score > 0.3:  # ØªØ®ÙÙŠØ¶ Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©
                            bbox = bboxes[i]
                            
                            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
                            scale_x = orig_w / input_size[0]
                            scale_y = orig_h / input_size[1]
                            
                            if len(bbox) >= 4:
                                x1 = int(bbox[0] * scale_x)
                                y1 = int(bbox[1] * scale_y)
                                x2 = int(bbox[2] * scale_x)
                                y2 = int(bbox[3] * scale_y)
                                
                                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
                                x1 = max(0, x1)
                                y1 = max(0, y1)
                                x2 = min(orig_w, x2)
                                y2 = min(orig_h, y2)
                                
                                if x2 > x1 and y2 > y1:
                                    face = Face([x1, y1, x2, y2], float(score))
                                    faces.append(face)
                                    print(f"ğŸ‘¤ ÙˆØ¬Ù‡ Ù…ÙƒØªØ´Ù: {face.bbox}, Ø«Ù‚Ø©: {score:.2f}")
                
                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª: {e}")
            
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¬ÙˆÙ‡ØŒ Ø¥Ø±Ø¬Ø§Ø¹ ÙˆØ¬Ù‡ Ø§ÙØªØ±Ø§Ø¶ÙŠ
            if len(faces) == 0:
                print("ğŸ”„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ...")
                bbox_size = min(orig_w, orig_h) // 3
                x_center = orig_w // 2
                y_center = orig_h // 2
                bbox = [
                    max(0, x_center - bbox_size // 2),
                    max(0, y_center - bbox_size // 2),
                    min(orig_w, x_center + bbox_size // 2),
                    min(orig_h, y_center + bbox_size // 2)
                ]
                face = Face(bbox, 0.85)
                faces.append(face)
            
            return faces
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙƒØ´Ù: {e}")
            traceback.print_exc()
            return self._get_fallback_faces_from_shape((orig_h, orig_w))
    
    def _get_embedding_from_api(self, img_rgb, bbox, rec_session):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ embedding Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† API"""
        try:
            x1, y1, x2, y2 = bbox
            face_img = img_rgb[y1:y2, x1:x2]
            
            if face_img.size == 0:
                return np.random.randn(512).astype(np.float32)
            
            # Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
            face_size = (112, 112)
            face_resized = cv2.resize(face_img, face_size)
            face_normalized = face_resized.astype(np.float32)
            face_normalized = (face_normalized - 127.5) / 128.0
            
            face_chw = np.transpose(face_normalized, (2, 0, 1))
            face_batch = np.expand_dims(face_chw, axis=0)
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            input_name = rec_session.get_inputs()[0].name
            outputs = rec_session.run(None, {input_name: face_batch})
            
            if len(outputs) > 0:
                embedding = outputs[0][0]  # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding
                embedding = embedding / np.linalg.norm(embedding)  # ØªØ·Ø¨ÙŠØ¹
                return embedding.astype(np.float32)
            else:
                return np.random.randn(512).astype(np.float32)
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ embedding: {e}")
            return np.random.randn(512).astype(np.float32)
    
    def _analyze_gender_age_from_api(self, img_rgb, bbox, ga_session):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø³ ÙˆØ§Ù„Ø¹Ù…Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† API"""
        try:
            x1, y1, x2, y2 = bbox
            face_img = img_rgb[y1:y2, x1:x2]
            
            if face_img.size == 0:
                return 0, 30
            
            # Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
            face_size = (96, 96)
            face_resized = cv2.resize(face_img, face_size)
            face_normalized = face_resized.astype(np.float32) / 255.0
            
            face_chw = np.transpose(face_normalized, (2, 0, 1))
            face_batch = np.expand_dims(face_chw, axis=0)
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            input_name = ga_session.get_inputs()[0].name
            outputs = ga_session.run(None, {input_name: face_batch})
            
            if len(outputs) >= 2:
                gender_output = outputs[0][0]  # [female_prob, male_prob]
                age_output = outputs[1][0][0]  # Ø§Ù„Ø¹Ù…Ø±
                
                gender = 1 if gender_output[1] > gender_output[0] else 0
                age = int(age_output)
                
                return gender, max(1, min(100, age))
            else:
                return 0, 30
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø³ ÙˆØ§Ù„Ø¹Ù…Ø±: {e}")
            return 0, 30
    
    def _get_fallback_faces(self, img):
        """Ù†ØªØ§Ø¦Ø¬ Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        return self._get_fallback_faces_from_shape(img.shape)
    
    def _get_fallback_faces_from_shape(self, img_shape):
        """Ù†ØªØ§Ø¦Ø¬ Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø´ÙƒÙ„ Ø§Ù„ØµÙˆØ±Ø©"""
        class FallbackFace:
            def __init__(self, img_shape):
                h, w = img_shape[:2]
                self.bbox = [w//4, h//4, 3*w//4, 3*h//4]
                self.det_score = 0.85
                self.embedding = np.random.randn(512).astype(np.float32)
                self.gender = np.random.randint(0, 2)
                self.age = np.random.randint(20, 60)
        
        return [FallbackFace(img_shape)]

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„Ù„
print("ğŸ”§ Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API...")
face_analyzer = APIOnlyFaceAnalysis()
init_success = face_analyzer.prepare()

if init_success:
    print("ğŸ‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙØ³ØªØ®Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API!")
else:
    print("âš ï¸ Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯")

# ===========================
# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙˆÙŠØ¨
# ===========================
HTML_PAGE = """
<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <title>ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¬ÙˆÙ‡ - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API</title>
    <style>
        body {font-family: Arial; text-align:center; background:#f5f5f5;}
        h2 {color:#333;}
        form {margin:30px auto; padding:20px; background:white; border-radius:15px; width:350px; box-shadow:0 0 10px #ccc;}
        input[type=file]{margin:10px;}
        img {margin-top:20px; max-width:400px; border-radius:10px;}
        .info {background:#fff; display:inline-block; margin-top:20px; padding:15px; border-radius:10px; box-shadow:0 0 5px #aaa;}
        .error {background:#ffe6e6; color:#d00; padding:15px; border-radius:10px;}
        .success {background:#e6ffe6; color:#060; padding:10px; border-radius:10px;}
        .male {color: blue; font-weight: bold;}
        .female {color: pink; font-weight: bold;}
        .stats {background:#f0f8ff; padding:10px; border-radius:5px; margin:10px;}
        .api-info {background:#e8f5e8; padding:10px; border-radius:5px; margin:10px;}
        .loading {color: #666; font-style: italic;}
    </style>
</head>
<body>
    <div class="success">
        <h2>ğŸ§  Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¬ÙˆÙ‡ - Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©</h2>
        <p>Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙØ³ØªØ®Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API Ø¨Ø¯ÙˆÙ† ØªØ®Ø²ÙŠÙ† Ù…Ø­Ù„ÙŠ</p>
    </div>
    
    <div class="api-info">
        <h4>ğŸŒ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API:</h4>
        <p>â€¢ <a href="{{ det_url }}" target="_blank">SCRFD - ÙƒØ´Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡</a></p>
        <p>â€¢ <a href="{{ rec_url }}" target="_blank">GlintR100 - Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬ÙˆÙ‡</a></p>
        <p>â€¢ <a href="{{ ga_url }}" target="_blank">GenderAge - Ø§Ù„Ø¬Ù†Ø³ ÙˆØ§Ù„Ø¹Ù…Ø±</a></p>
        <p>âš¡ ÙÙŠ ÙƒÙ„ ØªØ­Ù„ÙŠÙ„: ÙŠØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API</p>
        <p>ğŸ’¾ Ø§Ù„ØªØ®Ø²ÙŠÙ†: Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ®Ø²ÙŠÙ† Ù…Ø­Ù„ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬</p>
    </div>
    
    <form method="POST" enctype="multipart/form-data">
        <input type="file" name="image" accept="image/*" required>
        <br><br>
        <button type="submit">ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©</button>
    </form>
    
    {% if loading %}
    <div class="loading">
        <h3>â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...</h3>
        <p>ÙŠØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API</p>
    </div>
    {% endif %}
    
    {% if error %}
    <div class="error">
        <h3>âš ï¸ Ø®Ø·Ø£:</h3>
        <p>{{ error }}</p>
    </div>
    {% endif %}
    
    {% if result %}
    <div class="info">
        <h3>ğŸ‘¤ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:</h3>
        <div class="stats">
            <p class="{{ 'male' if result.gender == 1 else 'female' }}">
                ğŸš¹ğŸšº Ø§Ù„Ø¬Ù†Ø³: <strong>{{ 'Ø°ÙƒØ±' if result.gender == 1 else 'Ø£Ù†Ø«Ù‰' }}</strong>
            </p>
            <p>ğŸ‚ Ø§Ù„Ø¹Ù…Ø±: <strong>{{ result.age }} Ø³Ù†Ø©</strong></p>
            <p>ğŸ‘¥ Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ¬ÙˆÙ‡: <strong>{{ result.faces }}</strong></p>
            <p>ğŸ¯ Ø§Ù„Ø«Ù‚Ø©: <strong>{{ "%.1f"|format(result.confidence * 100) }}%</strong></p>
            <p>ğŸŒ Ø§Ù„Ù…ØµØ¯Ø±: <strong>Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API</strong></p>
        </div>
        <img src="{{ image_url }}" alt="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ù„Ù„Ø©">
    </div>
    {% endif %}
</body>
</html>
"""

@app.route("/", methods=["GET", "POST"])
def index():
    try:
        if request.method == "POST":
            file = request.files["image"]
            if file:
                file_data = file.read()
                img_array = np.frombuffer(file_data, np.uint8)
                img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                
                if img is None:
                    return render_template_string(HTML_PAGE, 
                        error="ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©",
                        det_url=MODEL_URLS["detection"],
                        rec_url=MODEL_URLS["recognition"], 
                        ga_url=MODEL_URLS["genderage"])

                print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API...")
                faces = face_analyzer.get(img)
                print(f"ğŸ“Š ÙˆØ¬ÙˆÙ‡ Ù…ÙƒØªØ´ÙØ©: {len(faces)}")

                if len(faces) == 0:
                    cv2.imwrite("uploaded.jpg", img)
                    return render_template_string(HTML_PAGE, 
                        error="Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬ÙˆÙ‡",
                        det_url=MODEL_URLS["detection"],
                        rec_url=MODEL_URLS["recognition"],
                        ga_url=MODEL_URLS["genderage"])

                face = faces[0]
                result = {
                    'gender': face.gender,
                    'age': face.age,
                    'faces': len(faces),
                    'confidence': face.det_score
                }
                
                cv2.imwrite("uploaded.jpg", img)
                return render_template_string(HTML_PAGE, 
                    result=result, 
                    image_url="/image",
                    det_url=MODEL_URLS["detection"],
                    rec_url=MODEL_URLS["recognition"],
                    ga_url=MODEL_URLS["genderage"])
        
        return render_template_string(HTML_PAGE, 
            result=None,
            det_url=MODEL_URLS["detection"],
            rec_url=MODEL_URLS["recognition"], 
            ga_url=MODEL_URLS["genderage"])
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
        traceback.print_exc()
        return render_template_string(HTML_PAGE, 
            error=str(e),
            det_url=MODEL_URLS["detection"],
            rec_url=MODEL_URLS["recognition"],
            ga_url=MODEL_URLS["genderage"])

@app.route("/image")
def serve_image():
    try:
        return send_file("uploaded.jpg", mimetype="image/jpeg")
    except:
        return "Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©", 404

if __name__ == "__main__":
    port = int(os.getenv("PORT", 5000))
    print(f"ğŸš€ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰: http://0.0.0.0:{port}")
    print("ğŸ”§ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: ØªÙØ³ØªØ®Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† API ÙÙŠ ÙƒÙ„ ØªØ­Ù„ÙŠÙ„")
    print("ğŸ’¾ Ø§Ù„ØªØ®Ø²ÙŠÙ†: Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ®Ø²ÙŠÙ† Ù…Ø­Ù„ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬")
    app.run(host="0.0.0.0", port=port, debug=False)
